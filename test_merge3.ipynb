{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eac780-eb88-4f4f-9d94-831951882d6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î°úÎ¥á Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\n",
      "GST_ARGUS: Cleaning up\n",
      "CONSUMER: Done Success\n",
      "GST_ARGUS: Done Success\n",
      "GST_ARGUS: Creating output stream\n",
      "CONSUMER: Waiting until producer is connected...\n",
      "GST_ARGUS: Available Sensor modes :\n",
      "GST_ARGUS: 3264 x 2464 FR = 21.000000 fps Duration = 47619048 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 3264 x 1848 FR = 28.000001 fps Duration = 35714284 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1920 x 1080 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1640 x 1232 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 59.999999 fps Duration = 16666667 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 120.000005 fps Duration = 8333333 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: Running with following settings:\n",
      "   Camera index = 0 \n",
      "   Camera mode  = 5 \n",
      "   Output Stream W = 1280 H = 720 \n",
      "   seconds to Run    = 0 \n",
      "   Frame Rate = 120.000005 \n",
      "GST_ARGUS: Setup Complete, Starting captures for 0 seconds\n",
      "GST_ARGUS: Starting repeat capture requests.\n",
      "CONSUMER: Producer has connected; continuing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@255.821] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n",
      "[ WARN:0@255.823] global cap_gstreamer.cpp:2152 setProperty OpenCV | GStreamer warning: GStreamer: unhandled property\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052d9e44ece040ea99cb9a8397d53e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', layout=\"Layout(height='480px', width='640px')\"), Image(value=b'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Ï£ºÌñâ + YOLO + ArUco ÏãúÏä§ÌÖú Ïã§Ìñâ\n",
      "[POTHOLE] Í∞êÏßÄ: white_frac=0.000 baseline=0.000 ‚Üí ÌöåÌîº ÏàòÌñâ\n",
      "[AVOID] Ìè¨Ìä∏ÌôÄ ÌöåÌîº ÏãúÏûë (Ï¢åÌöåÏ†Ñ)\n",
      "[AVOID] ÌöåÌîº ÏôÑÎ£å\n",
      "\n",
      "0: 320x416 1 car, 1 hazmat, 73.3ms\n",
      "Speed: 12.1ms preprocess, 73.3ms inference, 6.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'hazmat': 1, 'car': 1}\n",
      "\n",
      "0: 320x416 1 hazmat, 68.0ms\n",
      "Speed: 6.9ms preprocess, 68.0ms inference, 8.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'hazmat': 1}\n",
      "\n",
      "0: 320x416 1 car, 1 hazmat, 68.0ms\n",
      "Speed: 7.2ms preprocess, 68.0ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'hazmat': 1, 'car': 1}\n",
      "[POINT] alpha ÏµúÏ¥à ÌÜµÍ≥º ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ°\n",
      "[SEND] alpha ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ï§ë‚Ä¶\n",
      "[Server Response] {\"filename\":\"alpha.json\",\"message\":\"JSON uploaded successfully\"}\n",
      "\n",
      "\n",
      "0: 320x416 1 hazmat, 68.0ms\n",
      "Speed: 7.1ms preprocess, 68.0ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'hazmat': 1}\n",
      "\n",
      "0: 320x416 1 hazmat, 69.1ms\n",
      "Speed: 7.0ms preprocess, 69.1ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'hazmat': 1}\n",
      "\n",
      "0: 320x416 1 hazmat, 68.0ms\n",
      "Speed: 7.3ms preprocess, 68.0ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'hazmat': 1}\n",
      "\n",
      "0: 320x416 1 hazmat, 1 tank, 68.3ms\n",
      "Speed: 7.5ms preprocess, 68.3ms inference, 6.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'hazmat': 1, 'tank': 1}\n",
      "[POINT] sector1 ÏµúÏ¥à ÌÜµÍ≥º ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ°\n",
      "[SEND] sector1 ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ï§ë‚Ä¶\n",
      "[Server Response] {\"filename\":\"sector1.json\",\"message\":\"JSON uploaded successfully\"}\n",
      "\n",
      "\n",
      "0: 320x416 1 hazmat, 67.9ms\n",
      "Speed: 8.2ms preprocess, 67.9ms inference, 7.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'hazmat': 1}\n",
      "\n",
      "0: 320x416 (no detections), 68.9ms\n",
      "Speed: 6.9ms preprocess, 68.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 69.1ms\n",
      "Speed: 7.8ms preprocess, 69.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 tank, 68.1ms\n",
      "Speed: 7.4ms preprocess, 68.1ms inference, 6.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'tank': 1}\n",
      "\n",
      "0: 320x416 1 tank, 68.1ms\n",
      "Speed: 7.0ms preprocess, 68.1ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'tank': 1}\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 7.1ms preprocess, 67.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 tank, 68.1ms\n",
      "Speed: 7.1ms preprocess, 68.1ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'tank': 1}\n",
      "[POINT] sector2 ÏµúÏ¥à ÌÜµÍ≥º ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ°\n",
      "[SEND] sector2 ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ï§ë‚Ä¶\n",
      "[Server Response] {\"filename\":\"sector2.json\",\"message\":\"JSON uploaded successfully\"}\n",
      "\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 7.9ms preprocess, 68.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.1ms\n",
      "Speed: 6.9ms preprocess, 68.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 69.1ms\n",
      "Speed: 6.9ms preprocess, 69.1ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 69.0ms\n",
      "Speed: 7.1ms preprocess, 69.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.1ms\n",
      "Speed: 7.0ms preprocess, 68.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.1ms\n",
      "Speed: 6.6ms preprocess, 68.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 7.2ms preprocess, 67.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 7.2ms preprocess, 68.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 7.7ms preprocess, 67.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.2ms\n",
      "Speed: 7.3ms preprocess, 68.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.1ms\n",
      "Speed: 7.8ms preprocess, 68.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.1ms\n",
      "Speed: 7.1ms preprocess, 68.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.8ms\n",
      "Speed: 7.0ms preprocess, 67.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 69.1ms\n",
      "Speed: 8.0ms preprocess, 69.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 69.3ms\n",
      "Speed: 6.9ms preprocess, 69.3ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 8.1ms preprocess, 67.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.8ms\n",
      "Speed: 7.0ms preprocess, 67.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 7.8ms preprocess, 67.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 6.7ms preprocess, 68.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 6.9ms preprocess, 68.0ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.2ms\n",
      "Speed: 6.8ms preprocess, 68.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 6.9ms preprocess, 68.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 69.3ms\n",
      "Speed: 8.5ms preprocess, 69.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.7ms\n",
      "Speed: 6.9ms preprocess, 67.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 6.9ms preprocess, 67.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.4ms\n",
      "Speed: 7.5ms preprocess, 68.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[POINT] sector4 ÏµúÏ¥à ÌÜµÍ≥º ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ°\n",
      "[SEND] sector4 ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ï§ë‚Ä¶\n",
      "[Server Response] {\"filename\":\"sector4.json\",\"message\":\"JSON uploaded successfully\"}\n",
      "\n",
      "\n",
      "0: 320x416 (no detections), 67.8ms\n",
      "Speed: 7.0ms preprocess, 67.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 7.0ms preprocess, 67.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.8ms\n",
      "Speed: 6.8ms preprocess, 67.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.1ms\n",
      "Speed: 7.0ms preprocess, 68.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 tank, 69.4ms\n",
      "Speed: 7.0ms preprocess, 69.4ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'tank': 1}\n",
      "\n",
      "0: 320x416 1 tank, 68.1ms\n",
      "Speed: 6.8ms preprocess, 68.1ms inference, 8.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'tank': 1}\n",
      "\n",
      "0: 320x416 1 tank, 68.6ms\n",
      "Speed: 6.9ms preprocess, 68.6ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'tank': 1}\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 7.0ms preprocess, 67.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 7.2ms preprocess, 67.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 missile, 1 mortar, 68.0ms\n",
      "Speed: 7.5ms preprocess, 68.0ms inference, 8.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1, 'mortar': 1}\n",
      "\n",
      "0: 320x416 1 missile, 1 mortar, 67.9ms\n",
      "Speed: 6.9ms preprocess, 67.9ms inference, 9.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1, 'mortar': 1}\n",
      "\n",
      "0: 320x416 1 missile, 1 mortar, 67.8ms\n",
      "Speed: 6.8ms preprocess, 67.8ms inference, 8.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'mortar': 1, 'missile': 1}\n",
      "[POINT] sector5 ÏµúÏ¥à ÌÜµÍ≥º ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ°\n",
      "[SEND] sector5 ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ï§ë‚Ä¶\n",
      "[Server Response] {\"filename\":\"sector5.json\",\"message\":\"JSON uploaded successfully\"}\n",
      "\n",
      "\n",
      "0: 320x416 2 missiles, 1 mortar, 68.1ms\n",
      "Speed: 7.0ms preprocess, 68.1ms inference, 7.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'mortar': 1, 'missile': 2}\n",
      "\n",
      "0: 320x416 2 missiles, 1 mortar, 68.3ms\n",
      "Speed: 8.1ms preprocess, 68.3ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'mortar': 1, 'missile': 2}\n",
      "\n",
      "0: 320x416 2 missiles, 1 mortar, 67.8ms\n",
      "Speed: 7.0ms preprocess, 67.8ms inference, 6.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'mortar': 1, 'missile': 2}\n",
      "\n",
      "0: 320x416 1 missile, 1 mortar, 67.9ms\n",
      "Speed: 6.8ms preprocess, 67.9ms inference, 6.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1, 'mortar': 1}\n",
      "\n",
      "0: 320x416 3 missiles, 68.0ms\n",
      "Speed: 7.0ms preprocess, 68.0ms inference, 8.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 3}\n",
      "\n",
      "0: 320x416 (no detections), 69.1ms\n",
      "Speed: 7.6ms preprocess, 69.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 missile, 67.9ms\n",
      "Speed: 6.8ms preprocess, 67.9ms inference, 6.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 68.1ms\n",
      "Speed: 7.8ms preprocess, 68.1ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 (no detections), 67.9ms\n",
      "Speed: 7.3ms preprocess, 67.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 missile, 68.2ms\n",
      "Speed: 7.6ms preprocess, 68.2ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 1 tank, 68.0ms\n",
      "Speed: 7.3ms preprocess, 68.0ms inference, 6.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'tank': 1, 'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 68.0ms\n",
      "Speed: 6.9ms preprocess, 68.0ms inference, 8.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 1 tank, 69.1ms\n",
      "Speed: 6.9ms preprocess, 69.1ms inference, 8.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'tank': 1, 'missile': 1}\n",
      "[POINT] sector6 ÏµúÏ¥à ÌÜµÍ≥º ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ°\n",
      "[SEND] sector6 ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ï§ë‚Ä¶\n",
      "[Server Response] {\"filename\":\"sector6.json\",\"message\":\"JSON uploaded successfully\"}\n",
      "\n",
      "\n",
      "0: 320x416 1 missile, 1 tank, 68.5ms\n",
      "Speed: 6.9ms preprocess, 68.5ms inference, 8.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'tank': 1, 'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 68.1ms\n",
      "Speed: 7.6ms preprocess, 68.1ms inference, 5.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 68.0ms\n",
      "Speed: 7.7ms preprocess, 68.0ms inference, 7.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 67.8ms\n",
      "Speed: 7.3ms preprocess, 67.8ms inference, 5.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 (no detections), 69.3ms\n",
      "Speed: 7.3ms preprocess, 69.3ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[POINT] bravo ÏµúÏ¥à ÌÜµÍ≥º ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ°\n",
      "[SEND] bravo ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ï§ë‚Ä¶\n",
      "[Server Response] {\"filename\":\"bravo.json\",\"message\":\"JSON uploaded successfully\"}\n",
      "\n",
      "\n",
      "0: 320x416 1 missile, 68.0ms\n",
      "Speed: 7.1ms preprocess, 68.0ms inference, 7.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 68.0ms\n",
      "Speed: 7.1ms preprocess, 68.0ms inference, 6.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 68.0ms\n",
      "Speed: 7.0ms preprocess, 68.0ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 67.9ms\n",
      "Speed: 6.8ms preprocess, 67.9ms inference, 7.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "\n",
      "0: 320x416 1 missile, 69.2ms\n",
      "Speed: 7.2ms preprocess, 69.2ms inference, 6.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ: {'missile': 1}\n",
      "[POTHOLE] Í∞êÏßÄ: white_frac=0.014 baseline=0.109 ‚Üí ÌöåÌîº ÏàòÌñâ\n",
      "[AVOID] Ìè¨Ìä∏ÌôÄ ÌöåÌîº ÏãúÏûë (Ï¢åÌöåÏ†Ñ)\n",
      "[AVOID] ÌöåÌîº ÏôÑÎ£å\n",
      "\n",
      "0: 320x416 (no detections), 147.7ms\n",
      "Speed: 11.1ms preprocess, 147.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 70.4ms\n",
      "Speed: 6.9ms preprocess, 70.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.7ms\n",
      "Speed: 6.8ms preprocess, 67.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.2ms\n",
      "Speed: 6.9ms preprocess, 68.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.2ms\n",
      "Speed: 7.1ms preprocess, 68.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 6.8ms preprocess, 68.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.9ms\n",
      "Speed: 6.9ms preprocess, 68.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.2ms\n",
      "Speed: 7.2ms preprocess, 68.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.8ms\n",
      "Speed: 8.0ms preprocess, 67.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 6.9ms preprocess, 68.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 7.0ms preprocess, 68.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.4ms\n",
      "Speed: 6.7ms preprocess, 68.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.1ms\n",
      "Speed: 7.2ms preprocess, 68.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 7.1ms preprocess, 68.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.3ms\n",
      "Speed: 6.7ms preprocess, 68.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 69.2ms\n",
      "Speed: 7.1ms preprocess, 69.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 7.0ms preprocess, 68.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 67.7ms\n",
      "Speed: 6.9ms preprocess, 67.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.1ms\n",
      "Speed: 7.4ms preprocess, 68.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 70.2ms\n",
      "Speed: 6.9ms preprocess, 70.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.0ms\n",
      "Speed: 7.1ms preprocess, 68.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.1ms\n",
      "Speed: 6.8ms preprocess, 68.1ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 69.1ms\n",
      "Speed: 6.8ms preprocess, 69.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[POTHOLE] Í∞êÏßÄ: white_frac=0.026 baseline=0.109 ‚Üí ÌöåÌîº ÏàòÌñâ\n",
      "[AVOID] Ìè¨Ìä∏ÌôÄ ÌöåÌîº ÏãúÏûë (Ï¢åÌöåÏ†Ñ)\n",
      "[AVOID] ÌöåÌîº ÏôÑÎ£å\n",
      "\n",
      "0: 320x416 (no detections), 135.4ms\n",
      "Speed: 11.2ms preprocess, 135.4ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 68.5ms\n",
      "Speed: 7.0ms preprocess, 68.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "[END] ÌîÑÎ°úÍ∑∏Îû® Ï¢ÖÎ£å\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import os\n",
    "from tiki.mini import TikiMini\n",
    "from ultralytics import YOLO\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "os.environ['GST_DEBUG'] = '0'\n",
    "\n",
    "##############################################\n",
    "# 1. YOLOv8 ÌïôÏäµ Î™®Îç∏ Î°úÎìú (Í∞ÄÏû• Î®ºÏ†Ä Ïã§Ìñâ)\n",
    "##############################################\n",
    "model = YOLO(\"./best3.pt\")  # üî• ÌïôÏäµÌïú best.pt Í≤ΩÎ°ú ÌôïÏù∏\n",
    "\n",
    "##############################################\n",
    "# 2. ArUco ÏÑ§Ï†ï\n",
    "##############################################\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "aruco_params = cv2.aruco.DetectorParameters()\n",
    "aruco_detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params)\n",
    "\n",
    "marker_to_point = {\n",
    "    1: \"alpha\",\n",
    "    2: \"sector1\", 3: \"sector2\", 4: \"sector3\",\n",
    "    5: \"sector4\", 6: \"sector5\", 7: \"sector6\",\n",
    "    8: \"bravo\",\n",
    "    9: \"sector7\",\n",
    "    10: \"charlie\",\n",
    "    11: \"sector8\", 12: \"sector9\",\n",
    "    13: \"finish\"\n",
    "}\n",
    "\n",
    "visited_points = set()\n",
    "\n",
    "object_names = ['box', 'car', 'enemy', 'hazmat', 'missile', 'mortar', 'tank']\n",
    "\n",
    "##############################################\n",
    "# 4. Î°úÎ¥á Ï¥àÍ∏∞Ìôî\n",
    "##############################################\n",
    "tiki = TikiMini()\n",
    "tiki.set_motor_mode(tiki.MOTOR_MODE_PWM)\n",
    "print(\"Î°úÎ¥á Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\")\n",
    "\n",
    "# Ï£ºÌñâ ÌååÎùºÎØ∏ÌÑ∞\n",
    "base_speed = 70\n",
    "max_steering = 25\n",
    "frame_center_x = 160  # 320x240 Í∏∞Ï§Ä Ï§ëÏïô X\n",
    "\n",
    "# PID Ï†úÏñ¥\n",
    "class PIDController:\n",
    "    def __init__(self, kp=0.6, ki=0.0, kd=0.15):\n",
    "        self.kp = kp\n",
    "        self.ki = ki\n",
    "        self.kd = kd\n",
    "        self.integral = 0\n",
    "        self.prev_error = 0\n",
    "\n",
    "    def compute(self, error):\n",
    "        self.integral += error\n",
    "        derivative = error - self.prev_error\n",
    "        self.prev_error = error\n",
    "        self.integral = np.clip(self.integral, -200, 200)\n",
    "        return self.kp * error + self.ki * self.integral + self.kd * derivative\n",
    "\n",
    "pid = PIDController()\n",
    "\n",
    "##############################################\n",
    "# 5. ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ìï®Ïàò (ÌïÑÏöî Ïãú ÏÇ¨Ïö©)\n",
    "##############################################\n",
    "def send_to_server(point, detected_objects):\n",
    "    data = {\n",
    "        \"mission_code\": \"####\",\n",
    "        \"points\": [point],\n",
    "        \"detection\": detected_objects\n",
    "    }\n",
    "\n",
    "    json_content = json.dumps(data, indent=2, ensure_ascii=False)\n",
    "    files = {\n",
    "        'file': (f\"{point}.json\", json_content, 'application/json')\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(f\"[SEND] {point} ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ï§ë‚Ä¶\")\n",
    "        rsp = requests.post(\"http://58.229.150.23:5000/dashboard_json\", files=files, timeout=10)\n",
    "        print(\"[Server Response]\", rsp.text)\n",
    "    except Exception as e:\n",
    "        print(\"[ERROR] ÏÑúÎ≤Ñ Ï†ÑÏÜ° Ïã§Ìå®:\", e)\n",
    "\n",
    "##############################################\n",
    "# 6. Îã®Ïùº Ïπ¥Î©îÎùº ÌååÏù¥ÌîÑÎùºÏù∏ (Ï£ºÌñâ + YOLO Í≥µÏö©)\n",
    "##############################################\n",
    "pipeline = (\n",
    "    \"nvarguscamerasrc ! \"\n",
    "    \"video/x-raw(memory:NVMM), width=640, height=480, format=NV12, framerate=30/1 ! \"\n",
    "    \"nvvidconv ! video/x-raw, format=BGRx ! videoconvert ! \"\n",
    "    \"video/x-raw, format=BGR ! appsink drop=true max-buffers=1\"\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Ïπ¥Î©îÎùºÎ•º Ïó¥ Ïàò ÏóÜÏäµÎãàÎã§.\")\n",
    "\n",
    "# ÏµúÏã† ÌîÑÎ†àÏûÑÎßå ÏÇ¨Ïö©ÌïòÎèÑÎ°ù Î≤ÑÌçº ÏµúÏÜåÌôî\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "##############################################\n",
    "# 7. JupyterÏö© Îëê ÌôîÎ©¥ ÏúÑÏ†Ø (Ï£ºÌñâ / Í∞ùÏ≤¥Ïù∏Ïãù)\n",
    "##############################################\n",
    "drive_widget = widgets.Image(\n",
    "    format='jpeg',\n",
    "    layout=widgets.Layout(width='640px', height='480px')\n",
    ")\n",
    "yolo_widget = widgets.Image(\n",
    "    format='jpeg',\n",
    "    layout=widgets.Layout(width='640px', height='480px')\n",
    ")\n",
    "\n",
    "display(widgets.HBox([drive_widget, yolo_widget]))\n",
    "\n",
    "##############################################\n",
    "# 8. Bird's-Eye View ÏÑ§Ï†ï (Ï£ºÌñâÏö©)\n",
    "##############################################\n",
    "bird_width, bird_height = 320, 240\n",
    "\n",
    "src_points = np.float32([\n",
    "    [60, 120],\n",
    "    [260, 120],\n",
    "    [310, 230],\n",
    "    [10, 230],\n",
    "])\n",
    "\n",
    "dst_points = np.float32([\n",
    "    [0, 0],\n",
    "    [bird_width - 1, 0],\n",
    "    [bird_width - 1, bird_height - 1],\n",
    "    [0, bird_height - 1],\n",
    "])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "\n",
    "def frame_to_bytes_drive(frame):\n",
    "    \"\"\"Ï£ºÌñâ ÎîîÎ≤ÑÍ∑∏ Ìå®ÎÑê Ï†ÑÏÜ°Ïö© (ÎÇÆÏùÄ ÌíàÏßà, Î∂ÄÌïò Ï†ÅÏùå)\"\"\"\n",
    "    _, buf = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), 30])\n",
    "    return buf.tobytes()\n",
    "\n",
    "\n",
    "def frame_to_bytes_yolo(frame):\n",
    "    \"\"\"YOLO/ArUco ÏãúÍ∞ÅÌôîÏö© (Îçî ÎÜíÏùÄ ÌíàÏßà, ÏÇ¨ÎûåÏù¥ Î≥¥Í∏∞ Ï¢ãÍ≤å)\"\"\"\n",
    "    _, buf = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), 70])  # ÌïÑÏöîÏãú 60~80 ÏÇ¨Ïù¥ÏóêÏÑú Ï°∞Ï†à\n",
    "    return buf.tobytes()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   9) Ïä¨ÎùºÏù¥Îî© ÏúàÎèÑÏö∞ + ÏãúÍ∞ÅÌôî (Ï£ºÌñâÏö©)\n",
    "# ============================================================\n",
    "def sliding_window_center_with_vis(binary_mask, num_windows=8, margin=20, min_pixels=30):\n",
    "    h, w = binary_mask.shape[:2]\n",
    "    window_height = h // num_windows\n",
    "    ys, xs = np.where(binary_mask == 255)\n",
    "\n",
    "    vis = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    if len(xs) == 0:\n",
    "        return None, vis\n",
    "\n",
    "    bottom_thresh = int(h * 0.75)\n",
    "    bottom_inds = ys >= bottom_thresh\n",
    "    if np.any(bottom_inds):\n",
    "        current_x = int(np.mean(xs[bottom_inds]))\n",
    "    else:\n",
    "        current_x = int(np.mean(xs))\n",
    "\n",
    "    centers = []\n",
    "    pts = []\n",
    "\n",
    "    for i in range(num_windows):\n",
    "        y_low = h - (i + 1) * window_height\n",
    "        y_high = h - i * window_height\n",
    "        y_low = max(0, y_low)\n",
    "        if y_high <= y_low:\n",
    "            continue\n",
    "\n",
    "        inds = (ys >= y_low) & (ys < y_high)\n",
    "        win_xs = xs[inds]\n",
    "        if len(win_xs) == 0:\n",
    "            continue\n",
    "\n",
    "        x_min = max(0, current_x - margin)\n",
    "        x_max = min(w - 1, current_x + margin)\n",
    "\n",
    "        lane_inds = (win_xs >= x_min) & (win_xs <= x_max)\n",
    "        if np.sum(lane_inds) < min_pixels:\n",
    "            continue\n",
    "\n",
    "        current_x = int(np.mean(win_xs[lane_inds]))\n",
    "        centers.append(current_x)\n",
    "\n",
    "        cy = (y_low + y_high) // 2\n",
    "        pts.append((current_x, cy))\n",
    "\n",
    "        cv2.rectangle(vis, (x_min, y_low), (x_max, y_high), (0, 255, 0), 1)\n",
    "        cv2.circle(vis, (current_x, cy), 3, (255, 0, 255), -1)\n",
    "\n",
    "    if len(centers) == 0:\n",
    "        return int(np.mean(xs)), vis\n",
    "\n",
    "    pts_np = np.array(pts, np.int32)\n",
    "    cv2.polylines(vis, [pts_np], False, (255, 0, 255), 2)\n",
    "\n",
    "    return int(np.mean(centers)), vis\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   10) Ï§ëÏïô Ìù∞ÏÉâ ÎùºÏù∏ + ÎîîÎ≤ÑÍ∑∏Î∑∞ ÏÉùÏÑ± (Ï£ºÌñâÏö©)\n",
    "# ============================================================\n",
    "def detect_lane_center(frame_bgr, white_threshold=180):\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "\n",
    "    # ROI (ÌïòÎã®Î∂Ä)\n",
    "    roi_y1 = int(h * 0.60)\n",
    "    roi_y2 = h\n",
    "    roi_x1 = int(w * 0.10)\n",
    "    roi_x2 = int(w * 0.90)\n",
    "    roi = frame_bgr[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    roi_h, roi_w = roi.shape[:2]\n",
    "\n",
    "    # ‚ë† BGR -> HSV Î≥ÄÌôò\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Ìù∞ÏÉâÎßå ÎÇ®Í∏∞Í∏∞ ÏúÑÌïú Ï°∞Í±¥\n",
    "    S_MAX = 60\n",
    "    V_MIN = 180\n",
    "\n",
    "    lower_white = np.array([0, 0, V_MIN], dtype=np.uint8)\n",
    "    upper_white = np.array([180, S_MAX, 255], dtype=np.uint8)\n",
    "    white_mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "\n",
    "    # ÎÖ∏ÎûÄÏÉâ Ï†úÍ±∞ (ÌïÑÏöî Ïãú)\n",
    "    lower_yellow = np.array([15, 80, 80], dtype=np.uint8)\n",
    "    upper_yellow = np.array([40, 255, 255], dtype=np.uint8)\n",
    "    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    white_mask = cv2.bitwise_and(white_mask, cv2.bitwise_not(yellow_mask))\n",
    "    white_mask = cv2.GaussianBlur(white_mask, (5, 5), 0)\n",
    "\n",
    "    ys, xs = np.where(white_mask == 255)\n",
    "    white_mask_bgr = cv2.cvtColor(white_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    if len(xs) == 0:\n",
    "        return None, False, {\n",
    "            \"roi\": roi,\n",
    "            \"white\": white_mask_bgr,\n",
    "            \"sliding\": white_mask_bgr.copy(),\n",
    "        }\n",
    "\n",
    "    # Ïä¨ÎùºÏù¥Îî©ÏúàÎèÑÏö∞\n",
    "    center_x_rel, sliding_vis = sliding_window_center_with_vis(white_mask)\n",
    "\n",
    "    if center_x_rel is None:\n",
    "        center_x_rel = int(np.mean(xs))\n",
    "\n",
    "    center_x_frame = roi_x1 + center_x_rel\n",
    "\n",
    "    # Í∞ÄÎ°ú Ìù∞Ï§Ñ ÌåêÎã® (STOP LINE Îì±)\n",
    "    x_range = np.max(xs) - np.min(xs)\n",
    "    y_range = np.max(ys) - np.min(ys)\n",
    "    is_horizontal_bar = (x_range > roi_w * 0.6 and y_range < roi_h * 0.25)\n",
    "\n",
    "    return center_x_frame, is_horizontal_bar, {\n",
    "        \"roi\": roi,\n",
    "        \"white\": white_mask_bgr,\n",
    "        \"sliding\": sliding_vis,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   11) 2√ó2 ÎîîÎ≤ÑÍ∑∏ Ìå®ÎÑê ÏÉùÏÑ± (Ï£ºÌñâÏö©)\n",
    "# ============================================================\n",
    "def make_panel(bird, dbg):\n",
    "    def R(img):\n",
    "        return cv2.resize(img, (320, 240))\n",
    "\n",
    "    panel_top = cv2.hconcat([R(bird), R(dbg[\"roi\"])] )\n",
    "    panel_bot = cv2.hconcat([R(dbg[\"white\"]), R(dbg[\"sliding\"])])\n",
    "    return cv2.vconcat([panel_top, panel_bot])\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Improved Pothole detection (adaptive)\n",
    "# ------------------------------\n",
    "# Problems addressed:\n",
    "# - static absolute thresholds can falsely trigger when lane white is already thin\n",
    "# - use EMA baseline + relative drop + absolute minimum\n",
    "# - apply small morphology open to remove noise\n",
    "\n",
    "# state variables\n",
    "pothole_counter = 0\n",
    "pothole_last_time = 0.0\n",
    "POTHOLE_DETECT_FRAMES = 3       # Ïó∞ÏÜç ÌåêÏ†ï ÌîÑÎ†àÏûÑ Ïàò (Í∞êÎèÑ)\n",
    "POTHOLE_COOLDOWN = 9.0          # ÌöåÌîº ÌõÑ Ïû¨Í∞êÏßÄ ÎåÄÍ∏∞(sec)\n",
    "POTHOLE_MIN_ABS = 0.02          # Ï†àÎåÄ ÏµúÏÜå Ìù∞ÏÉâ ÎπÑÏú® (ÎÑàÎ¨¥ ÏûëÏùÄ Í∞íÏù¥Î©¥ Î¨¥Ïãú)\n",
    "POTHOLE_RATIO = 0.4             # Í∏∞Ï§Ä(EMA) ÎåÄÎπÑ Ïù¥ ÎπÑÏú®Î≥¥Îã§ ÏûëÏúºÎ©¥ Ìè¨Ìä∏ÌôÄÎ°ú ÌåêÎã®\n",
    "EMA_ALPHA = 0.05                # EMA ÏóÖÎç∞Ïù¥Ìä∏ Í≥ÑÏàò (Í∏∞Ï§Ä Ï†ÅÏùë ÏÜçÎèÑ)\n",
    "baseline_white = None           # EMA baseline for white fraction\n",
    "\n",
    "# morphology kernel\n",
    "_morph_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "\n",
    "\n",
    "def detect_pothole(frame_bgr):\n",
    "    \"\"\"Compute white fraction in ROI with noise filtering.\n",
    "    Returns: white_frac (0..1), roi_visual, mask_visual\n",
    "    \"\"\"\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    roi_y1 = int(h * 0.60)\n",
    "    roi_y2 = h\n",
    "    roi_x1 = int(w * 0.10)\n",
    "    roi_x2 = int(w * 0.90)\n",
    "    roi = frame_bgr[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    S_MAX = 60\n",
    "    V_MIN = 180\n",
    "    lower_white = np.array([0, 0, V_MIN], dtype=np.uint8)\n",
    "    upper_white = np.array([180, S_MAX, 255], dtype=np.uint8)\n",
    "    white_mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "\n",
    "    # ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞: open + small closing\n",
    "    white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_OPEN, _morph_kernel)\n",
    "    white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_CLOSE, _morph_kernel)\n",
    "\n",
    "    # optional: ignore very small components\n",
    "    # (connectedComponentsWithStats could be used, but heavier)\n",
    "\n",
    "    white_count = int(np.sum(white_mask == 255))\n",
    "    total = white_mask.size\n",
    "    white_frac = white_count / float(total) if total > 0 else 0.0\n",
    "\n",
    "    white_mask_bgr = cv2.cvtColor(white_mask, cv2.COLOR_GRAY2BGR)\n",
    "    return white_frac, roi, white_mask_bgr\n",
    "\n",
    "\n",
    "def should_trigger_pothole(white_frac):\n",
    "    \"\"\"Decide based on EMA baseline + absolute minimum and ratio.\"\"\"\n",
    "    global baseline_white\n",
    "    if baseline_white is None:\n",
    "        baseline_white = white_frac\n",
    "        return False\n",
    "\n",
    "    # Update baseline conservatively when white_frac is not very low\n",
    "    # This prevents fast baseline drop during true pothole events\n",
    "    if white_frac > baseline_white * 0.9:\n",
    "        baseline_white = EMA_ALPHA * white_frac + (1 - EMA_ALPHA) * baseline_white\n",
    "\n",
    "    threshold = max(POTHOLE_MIN_ABS, baseline_white * POTHOLE_RATIO)\n",
    "    return white_frac < threshold\n",
    "\n",
    "\n",
    "def avoid_pothole_left():\n",
    "    \"\"\"Left avoidance: stop -> short reverse -> gentle left sweep -> stop\n",
    "    Tweak timings/speeds to your robot.\n",
    "    \"\"\"\n",
    "    global pothole_last_time\n",
    "    print(\"[AVOID] Ìè¨Ìä∏ÌôÄ ÌöåÌîº ÏãúÏûë (Ï¢åÌöåÏ†Ñ)\")\n",
    "    try:\n",
    "        tiki.stop()\n",
    "        time.sleep(0.12)\n",
    "\n",
    "        # try short reverse if supported\n",
    "        try:\n",
    "            tiki.backward(50)\n",
    "            time.sleep(0.5)\n",
    "        except Exception:\n",
    "            tiki.stop()\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        # left sweep: left slower/backward, right forward -> gentle left\n",
    "        try:\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 10)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 60)\n",
    "            time.sleep(1.5)\n",
    "            tiki.forward(50)\n",
    "            time.sleep(2)\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 60)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 10)\n",
    "            time.sleep(1.5)\n",
    "            tiki.forward(50)\n",
    "            time.sleep(2)\n",
    "        except Exception:\n",
    "            tiki.stop()\n",
    "            time.sleep(0.3)\n",
    "\n",
    "        tiki.stop()\n",
    "    except Exception as e:\n",
    "        print(\"[AVOID][ERROR] ÌöåÌîºÏ§ë ÏòàÏô∏:\", e)\n",
    "        try:\n",
    "            tiki.stop()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    pothole_last_time = time.time()\n",
    "    print(\"[AVOID] ÌöåÌîº ÏôÑÎ£å\")\n",
    "\n",
    "\n",
    "##############################################\n",
    "# 12. Î©îÏù∏ Î£®ÌîÑ (Îã®Ïùº Ïπ¥Î©îÎùº ‚Üí Ï£ºÌñâ + YOLO Îëê ÌôîÎ©¥ Ï∂úÎ†•)\n",
    "##############################################\n",
    "print(\"[START] Ï£ºÌñâ + YOLO + ArUco ÏãúÏä§ÌÖú Ïã§Ìñâ\")\n",
    "\n",
    "frame_idx = 0\n",
    "annotated = None  # ÎßàÏßÄÎßâ YOLO Í≤∞Í≥º ÌîÑÎ†àÏûÑ Î≥¥Í¥Ä\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "            \n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "        # Í≥µÌÜµ ÏõêÎ≥∏ ÌîÑÎ†àÏûÑ (Ïπ¥Î©îÎùº Í∏∞Ï§Ä ÌöåÏ†Ñ Î≥¥Ï†ï)\n",
    "        frame = cv2.flip(frame, -1)\n",
    "\n",
    "        # Ï£ºÌñâÏö© Ï≤òÎ¶¨Î•º ÏúÑÌï¥ 320x240ÏúºÎ°ú Îã§Ïö¥Ïä§ÏºÄÏùºÌïú ÌîÑÎ†àÏûÑ ÏÇ¨Ïö©\n",
    "        frame_small = cv2.resize(frame, (bird_width, bird_height))\n",
    "\n",
    "        # ----- (1) Ï£ºÌñâÏö© Î≤ÑÎìúÎ∑∞ / Ï∞®ÏÑ† Ïù∏Ïãù -----\n",
    "        bird = cv2.warpPerspective(frame_small, M, (bird_width, bird_height))\n",
    "        center_x, is_horizontal_bar, dbg = detect_lane_center(bird)\n",
    "        view = bird.copy()\n",
    "\n",
    "        # ----- Ìè¨Ìä∏ÌôÄ Í∞êÏßÄ (Ï†ÅÏùëÌòï) -----\n",
    "        white_frac, _roi, _mask = detect_pothole(bird)\n",
    "        trigger = should_trigger_pothole(white_frac)\n",
    "\n",
    "        if trigger and (time.time() - pothole_last_time) > POTHOLE_COOLDOWN:\n",
    "            pothole_counter += 1\n",
    "        else:\n",
    "            pothole_counter = 0\n",
    "\n",
    "        if pothole_counter >= POTHOLE_DETECT_FRAMES:\n",
    "            print(f\"[POTHOLE] Í∞êÏßÄ: white_frac={white_frac:.3f} baseline={baseline_white:.3f} ‚Üí ÌöåÌîº ÏàòÌñâ\")\n",
    "            avoid_pothole_left()\n",
    "            pothole_counter = 0\n",
    "\n",
    "        if center_x is not None:\n",
    "            error = center_x - frame_center_x\n",
    "\n",
    "            steering = pid.compute(error)\n",
    "            steering *= 0.5\n",
    "            steering = float(np.clip(steering, -max_steering, max_steering))\n",
    "            if is_horizontal_bar:\n",
    "                steering = 0\n",
    "\n",
    "            L = int(np.clip(base_speed + steering, 0, 127))\n",
    "            Rm = int(np.clip(base_speed - steering, 0, 127))\n",
    "\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, L)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, Rm)\n",
    "        else:\n",
    "            tiki.stop()\n",
    "\n",
    "        panel = make_panel(view, dbg)\n",
    "\n",
    "        # ----- (2) Í∞ùÏ≤¥ Ïù∏Ïãù (YOLO + ArUco) : NÌîÑÎ†àÏûÑÎßàÎã§Îßå ÏàòÌñâ -----\n",
    "        frame_for_aruco = frame.copy()\n",
    "\n",
    "        # (A) ArUco Ìè¨Ïù∏Ìä∏ Í∞êÏßÄ (ÏõêÎ≥∏ Ìï¥ÏÉÅÎèÑ ÏÇ¨Ïö©)\n",
    "        corners, ids, _ = aruco_detector.detectMarkers(frame_for_aruco)\n",
    "\n",
    "        if ids is not None:\n",
    "            ids_list = [int(i[0]) for i in ids]\n",
    "\n",
    "            for marker_id in ids_list:\n",
    "                if marker_id in marker_to_point:\n",
    "                    point_name = marker_to_point[marker_id]\n",
    "\n",
    "                    if point_name not in visited_points:\n",
    "                        visited_points.add(point_name)\n",
    "                        print(f\"[POINT] {point_name} ÏµúÏ¥à ÌÜµÍ≥º ‚Üí ÏÑúÎ≤Ñ Ï†ÑÏÜ°\")\n",
    "                        send_to_server(point_name, {\"info\": \"passing point\"})\n",
    "\n",
    "            cv2.aruco.drawDetectedMarkers(frame_for_aruco, corners, ids)\n",
    "\n",
    "        # (B) YOLO Í∞ùÏ≤¥ Í∞êÏßÄ\n",
    "        if frame_idx % 5 == 0:\n",
    "            frame_for_yolo = frame.copy()\n",
    "            results = model(\n",
    "                frame_for_yolo,\n",
    "                conf=0.45,\n",
    "            )\n",
    "\n",
    "            detected_counts = defaultdict(int)\n",
    "            if results and len(results[0].boxes) > 0:\n",
    "                classes = results[0].boxes.cls.cpu().numpy()\n",
    "                for cls in classes:\n",
    "                    class_name = object_names[int(cls)]\n",
    "                    detected_counts[class_name] += 1\n",
    "            if len(detected_counts) > 0:\n",
    "                print(\"[DETECTION] Í∞ùÏ≤¥ Í∞êÏßÄ:\", dict(detected_counts))\n",
    "\n",
    "            annotated = results[0].plot()\n",
    "            cv2.putText(\n",
    "                annotated,\n",
    "                \"Object Detection\",\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (255, 0, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "        # ----- (3) Îëê ÌôîÎ©¥ÏùÑ Jupyter ÏúÑÏ†ØÏúºÎ°ú Ï∂úÎ†• -----\n",
    "        drive_widget.value = frame_to_bytes_drive(panel)\n",
    "        if annotated is not None and frame_idx % 2 == 0:\n",
    "            yolo_widget.value = frame_to_bytes_yolo(annotated)\n",
    "\n",
    "        time.sleep(0.02)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    tiki.stop()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[END] ÌîÑÎ°úÍ∑∏Îû® Ï¢ÖÎ£å\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec949b3-4985-42ae-99a1-02dcd398d913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
